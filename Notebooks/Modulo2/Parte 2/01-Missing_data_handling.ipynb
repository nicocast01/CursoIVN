{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este Notebook realizaremos Análisis de casos completos e Imputación por la media/mediana/moda, valor arbitrario, categoría dedicada, imputación aleatoria e indicador binario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# para mostrar todas las columnas del dataframe en el notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Para graficado\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para divisdir el conjunto de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Para la imputación de datos con sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import MissingIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando datos\n",
    "data = pd.read_csv('../../datasets/raw/credict_approval.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de variables y objetos en el dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos de datos\n",
    "print(data.dtypes,'\\n')\n",
    "print(data.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables con valores faltantes\n",
    "print(data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "       data\n",
    "       .isnull()\n",
    "       .sum()\n",
    "       .sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionemos el porcentaje de valores faltantes en cada variable\n",
    "data.isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfica de Proporción de valores nulos por variable\n",
    "(\n",
    "    data\n",
    "    .isnull()\n",
    "    .melt(value_name='missing')\n",
    "    .pipe(\n",
    "        lambda df: (\n",
    "            sns.displot(\n",
    "                data=df,\n",
    "                y='variable',\n",
    "                hue='missing',\n",
    "                multiple='fill',\n",
    "                aspect=2\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valores nulos en todo el conjunto de datos\n",
    "(\n",
    "    data\n",
    "    .isnull()\n",
    "    .pipe(\n",
    "        lambda df: sns.heatmap(data=df)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos las Variables con datos faltantes\n",
    "missin_value_vars = ['A14','A1','A2','A6','A7','A4','A5']\n",
    "numerical_features_with_missing_values = ['A2','A14']\n",
    "non_numerical_features_with_missing_values = ['A1','A6','A7','A4','A5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Casos Completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataset con casos completos\n",
    "data_cca = data.dropna()\n",
    "print('Número total de observaciones: {}'.format(len(data)))\n",
    "print('Número de observaciones con casos completos: {}'.format(len(data_cca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambien podemos indicar qué variables a considerar con casos completos\n",
    "data_cca = data.dropna(subset=numerical_features_with_missing_values)\n",
    "print('Number of total observations: {}'.format(len(data)))\n",
    "print('Number of observations with complete cases: {}'.format(len(data_cca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación por la media/mediana/moda utilizando Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separemos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[numerical_features_with_missing_values],\n",
    "    data['A16'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un objeto de clase SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Entrenemos al imputador sobre los datos de entrenamiento (aprenderá la mediana de todas las variables)\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# Observemos las medianas aprendidas:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos imputacion en los conjuntos de entrenamiento y prueba\n",
    "# NOTA: Los datos se regresan como numpy arrays!\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Corroboramos que los valores faltantes fueron imputados\n",
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación con la moda utilizando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento y prueba (variable categóricas)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[non_numerical_features_with_missing_values], data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el objeto de SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# entrenamos\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# observamos las modas aprendidas:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputamos en los conjuntos de entrenamiento y pruaba y verificamos la imputación\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación con Valor arbitrario usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en ctos. de entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[numerical_features_with_missing_values],\n",
    "    data['A16'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos y entrenamos el SimpleImputer\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=99)\n",
    "imputer.fit(X_train)\n",
    "\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputamos los conjuntos de entrenamiento y prueba (numpy arrays)\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# revisamos que los valores faltantes fueron imputados\n",
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quisiéramos continuar con nuestro análisis de datos, tendríamos que codificar X_train en un dataframe:\n",
    "X_train = pd.DataFrame(\n",
    "    X_train,\n",
    "    columns=imputer.get_feature_names_out(),  # the variable names\n",
    ")\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploremos los cambios en la distribución despues de la imputacion\n",
    "\n",
    "X_train.hist(bins=50, figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación con categoría dedicada usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separemos los datos en entrenamiento y prueba descritos sólo por las variables no numéricas\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[non_numerical_features_with_missing_values], data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancia de SimpleImputer y entrenamos\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# Vemos estadisticas:\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos la imputacion\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a un dataframe\n",
    "X_train = pd.DataFrame(\n",
    "    X_train,\n",
    "    columns=imputer.get_feature_names_out(),  # the variable names\n",
    ")\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación Aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deja de ejercicio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando un indicador binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('A16', axis=1), data['A16'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = MissingIndicator(error_on_new=True, features='missing-only')\n",
    "indicator.fit(X_train) \n",
    "\n",
    "# Podemos ver las variables con NaNs:\n",
    "# Los resultados muestran los índices de las columnas del numpy array\n",
    "\n",
    "indicator.features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_value_indicatord_dataset(dataset, trained_indicator):\n",
    "\n",
    "    # Creamos un nombre de columna para cada variable con valores faltantes\n",
    "    indicator_cols = [c+'_NA' for c in dataset.columns[trained_indicator.features_]]\n",
    "\n",
    "    # Concatenamos el conjunto de datos original con los indicadores de valores faltantes\n",
    "    dataset = pd.concat([\n",
    "    dataset.reset_index(),\n",
    "    pd.DataFrame(trained_indicator.transform(dataset), columns = indicator_cols)],\n",
    "    axis=1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicatedData= get_missing_value_indicatord_dataset(X_train,indicator)\n",
    "indicatedData.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos lo mismo para el cto. de prueba\n",
    "tmp = indicator.transform(X_test)\n",
    "\n",
    "X_test = pd.concat(\n",
    "    [\n",
    "        X_test.reset_index(),\n",
    "        pd.DataFrame(tmp, columns=indicator.get_feature_names_out()),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación por la media/moda + indicador binario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deja como ejercicio"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "190668de10e562b941b9fa78ebe98ef0bf1d742fd52dd3ccdc64dbf44346f9f3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
