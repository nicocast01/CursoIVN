{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este Notebook ejecutaremos codificación ordinal, one-hot y codificación por frecuencia y porcentajes, informada por el target y otras técnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Para la codificacion ordinal y one-hot usando sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Para dividir el conjunto de datos\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando datos\n",
    "data = pd.read_csv('../../datasets/raw/credict_approval.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación ordinal utilizando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una lista con las variables categóricas\n",
    "\n",
    "vars_categorical = ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['A16'], axis=1),  # predictores\n",
    "    data['A16'],  # target\n",
    "    test_size=0.3,  \n",
    "    random_state=0)  # seed para reproducibilidad\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos y entrenamos el codificador entero\n",
    "le = OrdinalEncoder()\n",
    "le.fit(X_train[vars_categorical])\n",
    "\n",
    "le.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos los sets de datos y visualizamos\n",
    "\n",
    "X_train_enc = le.transform(X_train[vars_categorical])\n",
    "X_test_enc = le.transform(X_test[vars_categorical])\n",
    "\n",
    "pd.DataFrame(X_train_enc, columns=vars_categorical).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificacion one-hot utilizando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el y entrenamos codificador\n",
    "\n",
    "encoder = OneHotEncoder(categories='auto',\n",
    "                        drop='first',  \n",
    "                        sparse_output=False)\n",
    "\n",
    "encoder.fit(X_train[vars_categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos las categorías aprendidas\n",
    "\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos e inspeccionamos los sets de datos\n",
    "\n",
    "X_train_enc = encoder.transform(X_train[vars_categorical])\n",
    "X_test_enc = encoder.transform(X_test[vars_categorical])\n",
    "\n",
    "pd.DataFrame(X_train_enc).head()\n",
    "#pd.DataFrame(X_test_enc).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos recuperar los nombres de las variables de la siguiente manera:\n",
    "\n",
    "encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos los valores más frecuentes de A7\n",
    "\n",
    "X_train[\"A7\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificación One hot categorías mas frecuentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_enc = OneHotEncoder(\n",
    "    handle_unknown=\"infrequent_if_exist\",  # categorías no vistas se tratarán como las menos frecuentes\n",
    "    max_categories=5,  # el número máximo de categorías\n",
    "    sparse_output=False,  \n",
    ")\n",
    "\n",
    "ohe_enc.set_output(transform=\"pandas\")\n",
    "\n",
    "ohe_enc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_enc.infrequent_categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificacación\n",
    "X_train = ohe_enc.transform(X_train)\n",
    "X_test = ohe_enc.transform(X_test)\n",
    "\n",
    "# exploremos los resultados\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificacion por frecuencia y porcentajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,  # datos completos\n",
    "    data['A16'],  # target\n",
    "    test_size=0.3,  \n",
    "    random_state=0)  # seed para reproducibilidad\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos funciones de procesamiento\n",
    "def count_mappings(df, variable):\n",
    "    return df[variable].value_counts().to_dict()\n",
    "\n",
    "\n",
    "def frequency_mappings(df, variable):\n",
    "    return (df[variable].value_counts() / len(df)).to_dict()\n",
    "\n",
    "\n",
    "def encode(train, test, variable, mapping):\n",
    "    train[variable] = train[variable].map(mapping)\n",
    "    test[variable] = test[variable].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificamos múltiples variables aplicando las funciones\n",
    "for variable in vars_categorical:\n",
    "    mappings = count_mappings(X_train, variable)\n",
    "    encode(X_train, X_test, variable, mappings)\n",
    "\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación informada por la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento y prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,  # datos completos\n",
    "    data['A16'],  # target\n",
    "    test_size=0.3,  \n",
    "    random_state=0)  # seed para reproducibilidad\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby(['A7'])['A16'].mean().plot()\n",
    "plt.title('Relación entre A7 y el target')\n",
    "plt.ylabel('Media del target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario con la media del target por categoría para la variable A7\n",
    "\n",
    "ordered_labels = X_train.groupby(['A7'])['A16'].mean().to_dict()\n",
    "\n",
    "ordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos las etiquetas con la media del target e inspeccionamos resultados\n",
    "\n",
    "X_train['A7'] = X_train['A7'].map(ordered_labels)\n",
    "X_test['A7'] = X_test['A7'].map(ordered_labels)\n",
    "\n",
    "X_train['A7'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.groupby(['A7'])['A16'].mean().plot()\n",
    "plt.title('Relación entre A7 y el target')\n",
    "plt.ylabel('Media del target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deja como ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación polar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deja como ejercicio"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d3da8fb9e8bfa1bb37ba2540b07cf657610f2258356e4813ced518687dfb04b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
